{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabf93de-0b26-4033-9cd0-8d247c43e4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from signals import *\n",
    "from frequencyestimator import *\n",
    "import time\n",
    "import copy\n",
    "import itertools\n",
    "from scipy.stats import binom\n",
    "from scipy.optimize import basinhopping\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "sns.set_context(\"poster\", font_scale = .45, rc={\"grid.linewidth\": 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8ac4c1-c266-4124-abe6-8afd2c12cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_angle(depths, n_samples, measurements, theta_found):\n",
    "\n",
    "    p_o2 = np.cos((2 * depths + 1) * (theta_found / 2.0)) ** 2\n",
    "    p_o4 = np.cos((2 * depths + 1) * (theta_found / 4.0)) ** 2\n",
    "    p_same = np.cos((2 * depths + 1) * (theta_found)) ** 2\n",
    "    p_s2 = np.cos((2 * depths + 1) * (np.pi / 2 - theta_found)) ** 2\n",
    "    p_s4 = np.cos((2 * depths + 1) * (np.pi / 4 - theta_found)) ** 2\n",
    "    p_s2_o2 = np.cos((2 * depths + 1) * (np.pi / 2 - theta_found / 2)) ** 2\n",
    "    p_s4_o2 = np.cos((2 * depths + 1) * (np.pi / 4 - theta_found/ 2)) ** 2\n",
    "\n",
    "    l_o2 = np.sum(\n",
    "        np.log(\n",
    "            [1e-75+binom.pmf(n_samples[kk] * measurements[kk], n_samples[kk], p_o2[kk]) for\n",
    "             kk in\n",
    "             range(len(n_samples))]))\n",
    "    l_o4 = np.sum(\n",
    "        np.log(\n",
    "            [1e-75+binom.pmf(n_samples[kk] * measurements[kk], n_samples[kk], p_o4[kk]) for\n",
    "             kk in\n",
    "             range(len(n_samples))]))\n",
    "    l_same = np.sum(\n",
    "        np.log(\n",
    "            [1e-75+binom.pmf(n_samples[kk] * measurements[kk], n_samples[kk], p_same[kk]) for\n",
    "             kk in\n",
    "             range(len(n_samples))]))\n",
    "    l_s2 = np.sum(\n",
    "        np.log(\n",
    "            [1e-75+binom.pmf(n_samples[kk] * measurements[kk], n_samples[kk], p_s2[kk]) for\n",
    "             kk in\n",
    "             range(len(n_samples))]))\n",
    "    l_s4 = np.sum(\n",
    "        np.log(\n",
    "            [1e-75+binom.pmf(n_samples[kk] * measurements[kk], n_samples[kk], p_s4[kk]) for\n",
    "             kk in\n",
    "             range(len(n_samples))]))\n",
    "    l_s2_o2 = np.sum(\n",
    "        np.log([1e-75+binom.pmf(n_samples[kk] * measurements[kk], n_samples[kk], p_s2_o2[kk])\n",
    "                for kk in\n",
    "                range(len(n_samples))]))\n",
    "    l_s4_o2 = np.sum(\n",
    "        np.log([1e-75+binom.pmf(n_samples[kk] * measurements[kk], n_samples[kk], p_s4_o2[kk])\n",
    "                for kk in\n",
    "                range(len(n_samples))]))\n",
    "\n",
    "\n",
    "    # which_correction = np.argmin([obj_same, obj_s2, obj_s4, obj_o2, obj_s2_o2, obj_s4_o2])\n",
    "    which_correction = np.argmax([l_same, l_s2, l_s4, l_o2, l_o4, l_s2_o2, l_s4_o2])\n",
    "    if which_correction == 1:\n",
    "        theta_found = np.pi / 2.0 - theta_found\n",
    "    elif which_correction == 2:\n",
    "        theta_found = np.pi / 4.0 - theta_found\n",
    "    elif which_correction == 3:\n",
    "        theta_found =  0.5 * theta_found\n",
    "    elif which_correction == 4:\n",
    "        theta_found =  0.25 * theta_found\n",
    "    elif which_correction == 5:\n",
    "        theta_found = np.pi / 2.0 - 0.5 * theta_found\n",
    "    elif which_correction == 6:\n",
    "        theta_found = np.pi / 4.0 - 0.5 * theta_found\n",
    "\n",
    "    return np.abs(theta_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ddb60f-0d52-4505-bd2b-1036105ac8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(lp, cos_top, sin_top, ula_signal, esprit):\n",
    "    sr = lp[:len(lp)//2]\n",
    "    si = lp[len(lp)//2:]\n",
    "\n",
    "    signal = ula_signal.signal\n",
    "\n",
    "    for i,j in enumerate(cos_top):\n",
    "        signal[j] = sr[i]*np.abs(np.real(signal[j])) + np.imag(signal[j])\n",
    "\n",
    "    for i,j in enumerate(sin_top):\n",
    "        signal[j] = np.real(signal[j]) + si[i]*np.abs(np.imag(signal[j]))\n",
    "    \n",
    "    # signal = sr * abs_cos + 1.0j * si * abs_sin\n",
    "    R = ula_signal.get_cov_matrix_toeplitz(signal)\n",
    "    _, _ = esprit.estimate_theta_toeplitz(R)\n",
    "    eigs = np.abs(esprit.eigs)[:2]\n",
    "    obj = eigs[1] - eigs[0]\n",
    "\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fcf5c4-607e-44b7-a74d-bef41ea19882",
   "metadata": {},
   "source": [
    "# Example Implementation\n",
    "\n",
    "Here we provide a minimal working example demonstrating how to use the code to estimate the amplitude using the ESPIRIT algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4492b90a-adc8-43b2-8251-1be9e5586583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.125 0.08 ]\n",
      "[0.22222222 0.125     ]\n",
      "objective: 259.06790295091054\n",
      "objective: 259.06790295091065\n",
      "objective: 259.0679029509108\n",
      "objective: 369.28551098484695\n",
      "objective: 369.285510984848\n",
      "objective: 369.2855109848483\n",
      "objective: 369.28551098484854\n",
      "sin est:   [ 1 -1 -1 -1  1  1  1 -1  1 -1  1]\n",
      "sin new:   [ 1 -1 -1 -1  1  1  1 -1  1 -1  1]\n",
      "sin exact: [ 1  1  1  1  1 -1  1  1  1  1  1]\n",
      "sin err:   [0.         0.00414815 0.01494169 0.03414352 0.04658152 0.\n",
      " 0.01367188 0.02314815 0.08       0.07407407 0.125     ]\n",
      "\n",
      "cos est:   [ 1  1  1  1  1 -1  1  1  1  1 -1]\n",
      "cos new:   [ 1  1  1  1  1 -1  1  1  1 -1 -1]\n",
      "cos exact: [ 1  1  1  1 -1 -1  1  1  1  1 -1]\n",
      "cos err:   [0.         0.00414815 0.01202624 0.03414352 0.040571   0.\n",
      " 0.01367188 0.02314815 0.048      0.22222222 0.125     ]\n",
      "\n",
      "[ 1  1  1  1  1 -1  1  1  1  1 -1]\n",
      "[ 1  1  1  1 -1 -1  1  1  1  1 -1]\n",
      "\n",
      "[ 1 -1 -1 -1  1  1  1 -1  1 -1  1]\n",
      "[ 1  1  1  1  1 -1  1  1  1  1  1]\n",
      "\n",
      "Array parameters: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Depths: [  0   1   2   4   8  16  32  64 128 256 512]\n",
      "Samples: [17, 15, 14, 12, 11, 9, 8, 6, 5, 3, 2]\n",
      "Number of queries: 6807\n",
      "theta: 0.03188428042925993\n",
      "Ave theta estimated: 0.02874458961338159\n",
      "a = 0.1; a_est = 0.09018110708024413\n",
      "Max Single Query: 512\n",
      "99% percentile: 9.818893e-03\n",
      "95% percentile: 9.818893e-03\n",
      "68% percentile: 9.818893e-03\n",
      "99% percentile constant: 66.837204\n",
      "95% percentile constant: 66.837204\n",
      "68% percentile constant: 66.837204\n",
      "99% percentile max constant: 5.027273\n",
      "95% percentile max constant: 5.027273\n",
      "68% percentile max constant: 5.027273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility\n",
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "# Set the per oracle noise parameter (See Eq. 18)\n",
    "# eta=1e-4\n",
    "eta=0\n",
    "# Set the array parameters (See Thm. II.2 and Eq. 12) \n",
    "narray = [3, 3, 3, 3, 2, 2, 2, 2]\n",
    "narray = [2]*10\n",
    "# Set the actual amplitude\n",
    "a=0.1\n",
    "theta = np.arcsin(a)\n",
    "niter=20\n",
    "\n",
    "# This sets up the simulation that simulates the measured amplitudes at the various physical locations.\n",
    "# It uses a C=1.5 value, which corresponds to the sampling schedule given in Eq. 16. The variable C here \n",
    "# is the parameter K in the paper.\n",
    "ula_signal = TwoqULASignal(M=narray, C=1.5)\n",
    "# Number of Monte Carlo trials used to estimate statistics. We tend to use 500 in the paper. Choose 100 here for speed.\n",
    "num_mc = 1\n",
    "thetas = np.zeros(num_mc, dtype = float)\n",
    "errors = np.zeros(num_mc, dtype = float)\n",
    "\n",
    "# Sets up the ESPIRIT object to estimate the amplitude\n",
    "espirit = ESPIRIT()\n",
    "\n",
    "optimize = True\n",
    "n_opt = 2\n",
    "\n",
    "for k in range(num_mc):\n",
    "    # n_samples = [500]*len(n_samples)\n",
    "    signal = ula_signal.estimate_signal(ula_signal.n_samples, theta, eta=eta, seed=seed+k)\n",
    "    # This estimates the covariance matrix of Eq. 8 using the approch given in DOI:10.1109/LSP.2015.2409153\n",
    "    R = ula_signal.get_cov_matrix_toeplitz(signal)\n",
    "    # This estimates the angle using the ESPIRIT algorithm\n",
    "    theta_est, _ = espirit.estimate_theta_toeplitz(R)\n",
    "    objective = np.abs(espirit.eigs[0]) - np.abs(espirit.eigs[1])\n",
    "    \n",
    "\n",
    "    if optimize:\n",
    "        sin_top = np.argsort(-ula_signal.signs_stderr['sin_est'])[:n_opt]\n",
    "        cos_top = np.argsort(-ula_signal.signs_stderr['cos_est'])[:n_opt]\n",
    "    \n",
    "    \n",
    "        print(ula_signal.signs_stderr['sin_est'][sin_top])\n",
    "        print(ula_signal.signs_stderr['cos_est'][cos_top])\n",
    "    \n",
    "        all_signs = [s for s in itertools.product([1.0, -1.0], repeat=2*n_opt)]\n",
    "        print(f'objective: {objective}')\n",
    "    \n",
    "        for signs in all_signs:\n",
    "            new_signal = np.array([x for x in ula_signal.signal])\n",
    "            new_cos_signs = np.array([x for x in ula_signal.signs['cos_est']])\n",
    "            new_sin_signs = np.array([x for x in ula_signal.signs['sin_est']])\n",
    "            for j in range(n_opt):\n",
    "                new_signal[j] = signs[2*j]*np.abs(np.real(new_signal[j])) + signs[2*j+1]*np.abs(np.imag(new_signal[j]))   \n",
    "                new_cos_signs[cos_top[j]] = signs[2*j]\n",
    "                new_sin_signs[cos_top[j]] = signs[2*j+1]\n",
    "                R = ula_signal.get_cov_matrix_toeplitz(new_signal)\n",
    "                # This estimates the angle using the ESPIRIT algorithm\n",
    "                theta_new, _ = espirit.estimate_theta_toeplitz(R)\n",
    "                objective_new = np.abs(espirit.eigs[0]) - np.abs(espirit.eigs[1])\n",
    "    \n",
    "                if objective_new > objective:\n",
    "                    cos_signs_found = np.array([x for x in new_cos_signs])\n",
    "                    sin_signs_found = np.array([x for x in new_sin_signs])\n",
    "                    theta_est = theta_new\n",
    "                    objective = objective_new\n",
    "                    print(f'objective: {objective}')\n",
    "    \n",
    "        print(f'sin est:   {ula_signal.signs[\"sin_est\"]}')\n",
    "        print(f'sin new:   {sin_signs_found}')\n",
    "        print(f'sin exact: {ula_signal.signs[\"sin_exact\"]}')\n",
    "        print(f'sin err:   {ula_signal.signs_stderr[\"sin_est\"]}')\n",
    "        print()\n",
    "        print(f'cos est:   {ula_signal.signs[\"cos_est\"]}')\n",
    "        print(f'cos new:   {cos_signs_found}')\n",
    "        print(f'cos exact: {ula_signal.signs[\"cos_exact\"]}')\n",
    "        print(f'cos err:   {ula_signal.signs_stderr[\"cos_est\"]}')\n",
    "        print()\n",
    "    \n",
    "    \n",
    "\n",
    "    # if optimize:\n",
    "    #     print(f'objective: {objective}')\n",
    "    #     abs_cos = np.abs(np.real(signal))\n",
    "    #     abs_sin = np.abs(np.imag(signal))\n",
    "    #     init_signs_cos = [s for s in ula_signal.signs['cos_est'][cos_top]]\n",
    "    #     init_signs_sin = [s for s in ula_signal.signs['sin_est'][sin_top]]\n",
    "    #     init_signs = np.array(init_signs_cos+init_signs_sin)\n",
    "    #     bounds = tuple((-1.0, 1.0) for _ in range(len(init_signs)))    \n",
    "    #     res = basinhopping(objective_function, init_signs, niter=niter, T=10.0, stepsize=1.0, \n",
    "    #                        minimizer_kwargs={'args': (cos_top, sin_top, ula_signal, espirit), \n",
    "    #                                          'bounds': bounds}, disp=True)\n",
    "    #     x = np.sign(res.x)\n",
    "    #     # signal = x[:len(init_signs)//2]*abs_cos + 1.0j * x[len(init_signs)//2:] * abs_sin\n",
    "    #     ula_signal.signs['cos_est'][cos_top] = x[:len(init_signs)//2]\n",
    "    #     ula_signal.signs['sin_est'][sin_top] = x[len(init_signs)//2:]\n",
    "    #     signal = np.array(ula_signal.signs['cos_est'])*abs_cos + 1.0j * np.array(ula_signal.signs['sin_est'])*abs_sin\n",
    "    #     R = ula_signal.get_cov_matrix_toeplitz(signal)\n",
    "    #     theta_est, _ = espirit.estimate_theta_toeplitz(R)\n",
    "    #     objective_basin = np.abs(espirit.eigs[0]) - np.abs(espirit.eigs[1])\n",
    "    #     print(f'basin objective: {objective_basin}')\n",
    "        \n",
    "    #     signal = np.array(ula_signal.signs['cos_exact'])*abs_cos + 1.0j * np.array(ula_signal.signs['sin_exact'])*abs_sin\n",
    "    #     R = ula_signal.get_cov_matrix_toeplitz(signal)\n",
    "    #     _, _ = espirit.estimate_theta_toeplitz(R)\n",
    "    #     objective_global = np.abs(espirit.eigs[0]) - np.abs(espirit.eigs[1])\n",
    "        \n",
    "    #     print(f'global objective: {objective_global}')\n",
    "       \n",
    "    # for kk in range(len(signal)-1):\n",
    "    #     signal_new = np.array([x for x in signal])\n",
    "    #     signal_new[kk+1] = np.conj(signal_new[kk+1])\n",
    "    #     R = ula_signal.get_cov_matrix_toeplitz(signal_new)\n",
    "    #     # This estimates the angle using the ESPIRIT algorithm\n",
    "    #     theta_new, eigs = espirit.estimate_theta_toeplitz(R)\n",
    "    #     objective_new = np.abs(espirit.eigs[0]) - np.abs(espirit.eigs[1])\n",
    "    #     if objective_new > objective:\n",
    "    #         objective = objective_new\n",
    "    #         # print(f'objective new: {objective_new}')\n",
    "    #         ula_signal.signs['sin_est'][kk]=-1\n",
    "    #         theta_est = theta_new\n",
    "        \n",
    "        \n",
    "    # R = ula_signal.get_cov_matrix_toeplitz(signal)\n",
    "    # # This estimates the angle using the ESPIRIT algorithm\n",
    "    # theta_est, eigs = espirit.estimate_theta_toeplitz(R)\n",
    "    # objective = np.abs(espirit.eigs[0]) - np.abs(espirit.eigs[1])\n",
    "    \n",
    "    theta_est = adjust_angle(ula_signal.depths, ula_signal.n_samples, ula_signal.measurements, theta_est)\n",
    "    # Estimate the error between estimated a and actual a\n",
    "    error = np.abs(np.sin(theta)-np.sin(theta_est)) \n",
    "    thetas[k] = theta_est            \n",
    "    errors[k] = error\n",
    "\n",
    "# Compute the total number of queries. The additional count of n_samples[0] is to \n",
    "# account for the fact that the Grover oracle has two invocations of the unitary U, but is \n",
    "# preceded by a single invocation of U (see Eq. 2 in paper). This accounts for the shots required\n",
    "# for that single U operator, which costs half as much as the Grover oracle.\n",
    "num_queries = 2*np.sum(np.array(ula_signal.depths)*np.array(ula_signal.n_samples)) + ula_signal.n_samples[0]\n",
    "# Compute the maximum single query\n",
    "max_single_query = np.max(ula_signal.depths)\n",
    "\n",
    "print(ula_signal.signs['cos_est'])\n",
    "print(ula_signal.signs['cos_exact'])\n",
    "print()\n",
    "print(ula_signal.signs['sin_est'])\n",
    "print(ula_signal.signs['sin_exact'])\n",
    "print()\n",
    "\n",
    "print(f'Array parameters: {narray}')\n",
    "print(f'Depths: {ula_signal.depths}')\n",
    "print(f'Samples: {ula_signal.n_samples}')\n",
    "print(f'Number of queries: {num_queries}')\n",
    "print(f'theta: {theta/np.pi}')\n",
    "print(f'Ave theta estimated: {np.mean(thetas)/np.pi}')\n",
    "print(f'a = {a}; a_est = {np.sin(np.mean(thetas))}')\n",
    "print(f'Max Single Query: {max_single_query}')\n",
    "print(f'99% percentile: {np.percentile(errors, 99):e}')\n",
    "print(f'95% percentile: {np.percentile(errors, 95):e}')\n",
    "print(f'68% percentile: {np.percentile(errors, 68):e}')\n",
    "print(f'99% percentile constant: {np.percentile(errors, 99)*num_queries:f}')\n",
    "print(f'95% percentile constant: {np.percentile(errors, 95)*num_queries:f}')\n",
    "print(f'68% percentile constant: {np.percentile(errors, 68)*num_queries:f}')\n",
    "print(f'99% percentile max constant: {np.percentile(errors, 99)*max_single_query:f}')\n",
    "print(f'95% percentile max constant: {np.percentile(errors, 95)*max_single_query:f}')\n",
    "print(f'68% percentile max constant: {np.percentile(errors, 68)*max_single_query:f}')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7df74-5821-408d-b876-049f56e22b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
